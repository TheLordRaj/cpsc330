
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Lecture 4: \(k\)-Nearest Neighbours and SVM RBFs &#8212; CPSC 330 Applied Machine Learning</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Lecture 5: Preprocessing and sklearn pipelines" href="05_preprocessing-pipelines.html" />
    <link rel="prev" title="Lecture 3: Machine Learning Fundamentals" href="03_ml-fundamentals.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/UBC-CS-logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">CPSC 330 Applied Machine Learning</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Things you should know
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../docs/README.html">
   CPSC 330 Documents
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Lectures
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="01_intro.html">
   Lecture 1: Course Introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="02_decision-trees.html">
   Lecture 2: Terminology, Baselines, Decision Trees
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="03_ml-fundamentals.html">
   Lecture 3: Machine Learning Fundamentals
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Lecture 4:
   <span class="math notranslate nohighlight">
    \(k\)
   </span>
   -Nearest Neighbours and SVM RBFs
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="05_preprocessing-pipelines.html">
   Lecture 5: Preprocessing and
   <code class="docutils literal notranslate">
    <span class="pre">
     sklearn
    </span>
   </code>
   pipelines
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="06_column-transformer-text-feats.html">
   Lecture 6:
   <code class="docutils literal notranslate">
    <span class="pre">
     sklearn
    </span>
   </code>
   <code class="docutils literal notranslate">
    <span class="pre">
     ColumnTransformer
    </span>
   </code>
   and Text Features
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="07_linear-models.html">
   Lecture 7: Linear Models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="08_hyperparameter-optimization.html">
   Lecture 8: Hyperparameter Optimization and Optimization Bias
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="09_classification-metrics.html">
   Lecture 9: Classification Metrics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="10_regression-metrics.html">
   Lecture 10: Regression Evaluation Metrics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="11_ensembles.html">
   Lecture 11: Ensembles
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="12_feat-importances.html">
   Lecture 12: Feature importances
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="13_feature-engineering-selection.html">
   Lecture 13: Feature engineering and feature selection
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="14_midterm-review.html">
   Lecture 14: Midterm review
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="15_K-Means.html">
   Lecture 15: K-Means Clustering
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="16_DBSCAN-hierarchical.html">
   Lecture 16: DBSCAN and Hierarchical Clustering
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="17_recommender-systems.html">
   Lecture 17: Recommender Systems
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="18_natural-language-processing.html">
   Lecture 18: Introduction to natural language processing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="19_intro_to_computer-vision.html">
   Lecture 19: Multi-class classification and introduction to computer vision
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="20_time-series.html">
   Lecture 20: Time series
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="21_survival-analysis.html">
   Lecture 21: Survival analysis
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="22_ethics.html">
   Lecture 22: Ethics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="23_communication.html">
   Lecture 23: Communication
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="24_deployment-conclusion.html">
   Lecture 24: Deployment and conclusion
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Attribution
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../attribution.html">
   Attributions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../LICENSE.html">
   LICENSE
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Varada Kolhatkar, CPSC 330 2022-23<br>Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/UBC-CS/cpsc330/master?urlpath=tree/lectures/04_kNNs-SVM-RBF.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../_sources/lectures/04_kNNs-SVM-RBF.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#imports-announcements-and-los">
   Imports, announcements, and LOs
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#imports">
     Imports
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#announcements">
     Announcements
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#learning-outcomes">
     Learning outcomes
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#quick-recap">
     Quick recap
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#motivation-and-distances-video">
   Motivation and distances [video]
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#analogy-based-models">
     Analogy-based models
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#analogy-based-algorithms-in-practice">
     Analogy-based algorithms in practice
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#general-idea-of-k-nearest-neighbours-algorithm">
     General idea of
     <span class="math notranslate nohighlight">
      \(k\)
     </span>
     -nearest neighbours algorithm
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#geometric-view-of-tabular-data-and-dimensions">
     Geometric view of tabular data and dimensions
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#dimensions-in-ml-problems">
     Dimensions in ML problems
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#feature-vectors">
     Feature vectors
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#similarity-between-examples">
     Similarity between examples
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#distance-between-feature-vectors">
     Distance between feature vectors
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#euclidean-distance">
     Euclidean distance
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#finding-the-nearest-neighbour">
     Finding the nearest neighbour
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#question">
     Question
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#finding-the-distances-to-a-query-point">
     Finding the distances to a query point
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#k-nearest-neighbours-k-nns-video">
   <span class="math notranslate nohighlight">
    \(k\)
   </span>
   -Nearest Neighbours (
   <span class="math notranslate nohighlight">
    \(k\)
   </span>
   -NNs) [video]
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#choosing-n-neighbors">
     Choosing
     <code class="docutils literal notranslate">
      <span class="pre">
       n_neighbors
      </span>
     </code>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#how-to-choose-n-neighbors">
     How to choose
     <code class="docutils literal notranslate">
      <span class="pre">
       n_neighbors
      </span>
     </code>
     ?
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#questions-for-you">
   ❓❓ Questions for you
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#iclicker-exercise-4-1">
     (iClicker) Exercise 4.1
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#break-5-min">
   Break (5 min)
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#more-on-k-nns-video">
   More on
   <span class="math notranslate nohighlight">
    \(k\)
   </span>
   -NNs [video]
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#other-useful-arguments-of-kneighborsclassifier">
     Other useful arguments of
     <code class="docutils literal notranslate">
      <span class="pre">
       KNeighborsClassifier
      </span>
     </code>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#regression-with-k-nearest-neighbours-k-nns">
     Regression with
     <span class="math notranslate nohighlight">
      \(k\)
     </span>
     -nearest neighbours (
     <span class="math notranslate nohighlight">
      \(k\)
     </span>
     -NNs)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#pros-of-k-nns-for-supervised-learning">
     Pros of
     <span class="math notranslate nohighlight">
      \(k\)
     </span>
     -NNs for supervised learning
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#cons-of-k-nns-for-supervised-learning">
     Cons of
     <span class="math notranslate nohighlight">
      \(k\)
     </span>
     -NNs for supervised learning
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#parametric-vs-non-parametric">
     Parametric vs non parametric
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#curse-of-dimensionality">
     Curse of dimensionality
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#support-vector-machines-svms-with-rbf-kernel-video">
   Support Vector Machines (SVMs) with RBF kernel [video]
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#overview">
     Overview
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#let-s-explore-svm-rbfs">
     Let’s explore SVM RBFs
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#decision-boundary-of-svms">
     Decision boundary of SVMs
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#support-vectors">
     Support vectors
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#hyperparameters-of-svm">
     Hyperparameters of SVM
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#relation-of-gamma-and-the-fundamental-trade-off">
     Relation of
     <code class="docutils literal notranslate">
      <span class="pre">
       gamma
      </span>
     </code>
     and the fundamental trade-off
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#relation-of-c-and-the-fundamental-trade-off">
     Relation of
     <code class="docutils literal notranslate">
      <span class="pre">
       C
      </span>
     </code>
     and the fundamental trade-off
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#search-over-multiple-hyperparameters">
     Search over multiple hyperparameters
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#svm-regressor">
     SVM Regressor
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id1">
   ❓❓ Questions for you
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#iclicker-exercise-4-2">
   (iClicker) Exercise 4.2
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#more-practice-questions">
     More practice questions
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#summary">
   Summary
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#coming-up">
     Coming up:
    </a>
   </li>
  </ul>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Lecture 4: k-Nearest Neighbours and SVM RBFs</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#imports-announcements-and-los">
   Imports, announcements, and LOs
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#imports">
     Imports
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#announcements">
     Announcements
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#learning-outcomes">
     Learning outcomes
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#quick-recap">
     Quick recap
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#motivation-and-distances-video">
   Motivation and distances [video]
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#analogy-based-models">
     Analogy-based models
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#analogy-based-algorithms-in-practice">
     Analogy-based algorithms in practice
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#general-idea-of-k-nearest-neighbours-algorithm">
     General idea of
     <span class="math notranslate nohighlight">
      \(k\)
     </span>
     -nearest neighbours algorithm
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#geometric-view-of-tabular-data-and-dimensions">
     Geometric view of tabular data and dimensions
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#dimensions-in-ml-problems">
     Dimensions in ML problems
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#feature-vectors">
     Feature vectors
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#similarity-between-examples">
     Similarity between examples
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#distance-between-feature-vectors">
     Distance between feature vectors
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#euclidean-distance">
     Euclidean distance
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#finding-the-nearest-neighbour">
     Finding the nearest neighbour
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#question">
     Question
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#finding-the-distances-to-a-query-point">
     Finding the distances to a query point
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#k-nearest-neighbours-k-nns-video">
   <span class="math notranslate nohighlight">
    \(k\)
   </span>
   -Nearest Neighbours (
   <span class="math notranslate nohighlight">
    \(k\)
   </span>
   -NNs) [video]
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#choosing-n-neighbors">
     Choosing
     <code class="docutils literal notranslate">
      <span class="pre">
       n_neighbors
      </span>
     </code>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#how-to-choose-n-neighbors">
     How to choose
     <code class="docutils literal notranslate">
      <span class="pre">
       n_neighbors
      </span>
     </code>
     ?
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#questions-for-you">
   ❓❓ Questions for you
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#iclicker-exercise-4-1">
     (iClicker) Exercise 4.1
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#break-5-min">
   Break (5 min)
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#more-on-k-nns-video">
   More on
   <span class="math notranslate nohighlight">
    \(k\)
   </span>
   -NNs [video]
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#other-useful-arguments-of-kneighborsclassifier">
     Other useful arguments of
     <code class="docutils literal notranslate">
      <span class="pre">
       KNeighborsClassifier
      </span>
     </code>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#regression-with-k-nearest-neighbours-k-nns">
     Regression with
     <span class="math notranslate nohighlight">
      \(k\)
     </span>
     -nearest neighbours (
     <span class="math notranslate nohighlight">
      \(k\)
     </span>
     -NNs)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#pros-of-k-nns-for-supervised-learning">
     Pros of
     <span class="math notranslate nohighlight">
      \(k\)
     </span>
     -NNs for supervised learning
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#cons-of-k-nns-for-supervised-learning">
     Cons of
     <span class="math notranslate nohighlight">
      \(k\)
     </span>
     -NNs for supervised learning
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#parametric-vs-non-parametric">
     Parametric vs non parametric
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#curse-of-dimensionality">
     Curse of dimensionality
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#support-vector-machines-svms-with-rbf-kernel-video">
   Support Vector Machines (SVMs) with RBF kernel [video]
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#overview">
     Overview
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#let-s-explore-svm-rbfs">
     Let’s explore SVM RBFs
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#decision-boundary-of-svms">
     Decision boundary of SVMs
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#support-vectors">
     Support vectors
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#hyperparameters-of-svm">
     Hyperparameters of SVM
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#relation-of-gamma-and-the-fundamental-trade-off">
     Relation of
     <code class="docutils literal notranslate">
      <span class="pre">
       gamma
      </span>
     </code>
     and the fundamental trade-off
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#relation-of-c-and-the-fundamental-trade-off">
     Relation of
     <code class="docutils literal notranslate">
      <span class="pre">
       C
      </span>
     </code>
     and the fundamental trade-off
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#search-over-multiple-hyperparameters">
     Search over multiple hyperparameters
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#svm-regressor">
     SVM Regressor
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id1">
   ❓❓ Questions for you
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#iclicker-exercise-4-2">
   (iClicker) Exercise 4.2
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#more-practice-questions">
     More practice questions
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#summary">
   Summary
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#coming-up">
     Coming up:
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <p><img alt="" src="../_images/330-banner.png" /></p>
<section class="tex2jax_ignore mathjax_ignore" id="lecture-4-k-nearest-neighbours-and-svm-rbfs">
<h1>Lecture 4: <span class="math notranslate nohighlight">\(k\)</span>-Nearest Neighbours and SVM RBFs<a class="headerlink" href="#lecture-4-k-nearest-neighbours-and-svm-rbfs" title="Permalink to this headline">#</a></h1>
<p>UBC 2022-23</p>
<p>Instructor: Varada Kolhatkar</p>
<blockquote>
<div><p>If two things are similar, the thought of one will tend to trigger the thought of the other <br>
– Aristotle</p>
</div></blockquote>
<section id="imports-announcements-and-los">
<h2>Imports, announcements, and LOs<a class="headerlink" href="#imports-announcements-and-los" title="Permalink to this headline">#</a></h2>
<section id="imports">
<h3>Imports<a class="headerlink" href="#imports" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">sys</span>

<span class="kn">import</span> <span class="nn">IPython</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">HTML</span>

<span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;code/.&quot;</span><span class="p">)</span>

<span class="kn">import</span> <span class="nn">ipywidgets</span> <span class="k">as</span> <span class="nn">widgets</span>
<span class="kn">import</span> <span class="nn">mglearn</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">display</span>
<span class="kn">from</span> <span class="nn">ipywidgets</span> <span class="kn">import</span> <span class="n">interact</span><span class="p">,</span> <span class="n">interactive</span>
<span class="kn">from</span> <span class="nn">plotting_functions</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sklearn.dummy</span> <span class="kn">import</span> <span class="n">DummyClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_validate</span><span class="p">,</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">utils</span> <span class="kn">import</span> <span class="o">*</span>

<span class="o">%</span><span class="k">matplotlib</span> inline

<span class="n">pd</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s2">&quot;display.max_colwidth&quot;</span><span class="p">,</span> <span class="mi">200</span><span class="p">)</span>
<span class="kn">import</span> <span class="nn">warnings</span>

<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><br><br></p>
</section>
<section id="announcements">
<h3>Announcements<a class="headerlink" href="#announcements" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>hw2 deadline is today at 11:59pm.</p></li>
<li><p>Class add/drop deadline is today.</p></li>
<li><p>hw3 will be released later today.</p>
<ul>
<li><p>The due date is going to be Monday, Oct 3.</p></li>
<li><p>I plan to allow group submission starting this homework.</p></li>
</ul>
</li>
</ul>
<p><br><br></p>
</section>
<section id="learning-outcomes">
<h3>Learning outcomes<a class="headerlink" href="#learning-outcomes" title="Permalink to this headline">#</a></h3>
<p>From this lecture, you will be able to</p>
<ul class="simple">
<li><p>explain the notion of similarity-based algorithms;</p></li>
<li><p>broadly describe how <span class="math notranslate nohighlight">\(k\)</span>-NNs use distances;</p></li>
<li><p>discuss the effect of using a small/large value of the hyperparameter <span class="math notranslate nohighlight">\(k\)</span> when using the <span class="math notranslate nohighlight">\(k\)</span>-NN algorithm;</p></li>
<li><p>describe the problem of curse of dimensionality;</p></li>
<li><p>explain the general idea of SVMs with RBF kernel;</p></li>
<li><p>broadly describe the relation of <code class="docutils literal notranslate"><span class="pre">gamma</span></code> and <code class="docutils literal notranslate"><span class="pre">C</span></code> hyperparameters of SVMs with the fundamental tradeoff.</p></li>
</ul>
<p><br><br></p>
</section>
<section id="quick-recap">
<h3>Quick recap<a class="headerlink" href="#quick-recap" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>Why do we split the data?</p></li>
<li><p>What are the 4 types of data we discussed last class?</p></li>
<li><p>What are the advantages of cross-validation?</p></li>
<li><p>What is overfitting?</p></li>
<li><p>What’s the fundamental trade-off in supervised machine learning?</p></li>
<li><p>What is the golden rule of machine learning?</p></li>
</ul>
<p><br><br></p>
<p><br><br></p>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>If you want to run this notebook you will have to install <code class="docutils literal notranslate"><span class="pre">ipywidgets</span></code>.
Follow the installation instructions <a class="reference external" href="https://ipywidgets.readthedocs.io/en/latest/user_install.html">here</a>.</p>
</div>
</section>
</section>
<section id="motivation-and-distances-video">
<h2>Motivation and distances [<a class="reference external" href="https://youtu.be/hCa3EXEUmQk">video</a>]<a class="headerlink" href="#motivation-and-distances-video" title="Permalink to this headline">#</a></h2>
<section id="analogy-based-models">
<h3>Analogy-based models<a class="headerlink" href="#analogy-based-models" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>Suppose you are given the following training examples with corresponding labels and are asked to label a given test example.</p></li>
</ul>
<p><img alt="" src="../_images/knn-motivation.png" /></p>
<!-- <img src='./img/knn-motivation.png' width="1000"> -->
<p><a class="reference external" href="https://vipl.ict.ac.cn/en/database.php">source</a></p>
<ul class="simple">
<li><p>An intuitive way to classify the test example is by finding the most “similar” example(s) from the training set and using that label for the test example.</p></li>
</ul>
</section>
<section id="analogy-based-algorithms-in-practice">
<h3>Analogy-based algorithms in practice<a class="headerlink" href="#analogy-based-algorithms-in-practice" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p><a class="reference external" href="https://www.hertasecurity.com/en">Herta’s High-tech Facial Recognition</a></p>
<ul>
<li><p>Feature vectors for human faces</p></li>
<li><p><span class="math notranslate nohighlight">\(k\)</span>-NN to identify which face is on their watch list</p></li>
</ul>
</li>
<li><p>Recommendation systems</p></li>
</ul>
<p><img alt="" src="../_images/hetra.png" /></p>
<!-- <img src='./img/hetra.png' width="500"> -->
<p><a class="reference external" href="https://hertasecurity.com/">source</a></p>
</section>
<section id="general-idea-of-k-nearest-neighbours-algorithm">
<h3>General idea of <span class="math notranslate nohighlight">\(k\)</span>-nearest neighbours algorithm<a class="headerlink" href="#general-idea-of-k-nearest-neighbours-algorithm" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>Consider the following toy dataset with two classes.</p>
<ul>
<li><p>blue circles <span class="math notranslate nohighlight">\(\rightarrow\)</span> class 0</p></li>
<li><p>red triangles <span class="math notranslate nohighlight">\(\rightarrow\)</span> class 1</p></li>
<li><p>green stars <span class="math notranslate nohighlight">\(\rightarrow\)</span> test examples</p></li>
</ul>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">mglearn</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">make_forge</span><span class="p">()</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">8.2</span><span class="p">,</span> <span class="mf">3.66214339</span><span class="p">],</span> <span class="p">[</span><span class="mf">9.9</span><span class="p">,</span> <span class="mf">3.2</span><span class="p">],</span> <span class="p">[</span><span class="mf">11.2</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">]])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_train_test_points</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">X_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/04_kNNs-SVM-RBF_19_0.png" src="../_images/04_kNNs-SVM-RBF_19_0.png" />
</div>
</div>
<ul class="simple">
<li><p>Given a new data point, predict the class of the data point by finding the “closest” data point in the training set, i.e., by finding its “nearest neighbour” or majority vote of nearest neighbours.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">n_neighbors</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">plot_knn_clf</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">n_neighbors</span><span class="o">=</span><span class="n">n_neighbors</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">interactive</span><span class="p">(</span>
    <span class="n">f</span><span class="p">,</span>
    <span class="n">n_neighbors</span><span class="o">=</span><span class="n">widgets</span><span class="o">.</span><span class="n">IntSlider</span><span class="p">(</span><span class="nb">min</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "c1f1fceb8d8a4da28b74af004498549c"}
</script></div>
</div>
</section>
<section id="geometric-view-of-tabular-data-and-dimensions">
<h3>Geometric view of tabular data and dimensions<a class="headerlink" href="#geometric-view-of-tabular-data-and-dimensions" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>To understand analogy-based algorithms it’s useful to think of data as points in a high dimensional space.</p></li>
<li><p>Our <code class="docutils literal notranslate"><span class="pre">X</span></code> represents the problem in terms of relevant <strong>features</strong> (<span class="math notranslate nohighlight">\(d\)</span>) with one dimension for each <strong>feature</strong> (column).</p></li>
<li><p>Examples are <strong>points in a <span class="math notranslate nohighlight">\(d\)</span>-dimensional space</strong>.</p></li>
</ul>
<p>How many dimensions (features) are there in the cities data?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cities_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;data/canada_usa_cities.csv&quot;</span><span class="p">)</span>
<span class="n">X_cities</span> <span class="o">=</span> <span class="n">cities_df</span><span class="p">[[</span><span class="s2">&quot;longitude&quot;</span><span class="p">,</span> <span class="s2">&quot;latitude&quot;</span><span class="p">]]</span>
<span class="n">y_cities</span> <span class="o">=</span> <span class="n">cities_df</span><span class="p">[</span><span class="s2">&quot;country&quot;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mglearn</span><span class="o">.</span><span class="n">discrete_scatter</span><span class="p">(</span><span class="n">X_cities</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_cities</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">y_cities</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;longitude&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;latitude&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/04_kNNs-SVM-RBF_26_0.png" src="../_images/04_kNNs-SVM-RBF_26_0.png" />
</div>
</div>
<ul class="simple">
<li><p>Recall the <a class="reference external" href="https://www.kaggle.com/geomack/spotifyclassification/home">Spotify Song Attributes</a> dataset from homework 1.</p></li>
<li><p>How many dimensions (features) we used in the homework?</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">spotify_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;data/spotify.csv&quot;</span><span class="p">,</span> <span class="n">index_col</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">X_spotify</span> <span class="o">=</span> <span class="n">spotify_df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;target&quot;</span><span class="p">,</span> <span class="s2">&quot;song_title&quot;</span><span class="p">,</span> <span class="s2">&quot;artist&quot;</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The number of features in the Spotify dataset: </span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">X_spotify</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">X_spotify</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>The number of features in the Spotify dataset: 13
</pre></div>
</div>
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>acousticness</th>
      <th>danceability</th>
      <th>duration_ms</th>
      <th>energy</th>
      <th>instrumentalness</th>
      <th>key</th>
      <th>liveness</th>
      <th>loudness</th>
      <th>mode</th>
      <th>speechiness</th>
      <th>tempo</th>
      <th>time_signature</th>
      <th>valence</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.0102</td>
      <td>0.833</td>
      <td>204600</td>
      <td>0.434</td>
      <td>0.021900</td>
      <td>2</td>
      <td>0.1650</td>
      <td>-8.795</td>
      <td>1</td>
      <td>0.4310</td>
      <td>150.062</td>
      <td>4.0</td>
      <td>0.286</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.1990</td>
      <td>0.743</td>
      <td>326933</td>
      <td>0.359</td>
      <td>0.006110</td>
      <td>1</td>
      <td>0.1370</td>
      <td>-10.401</td>
      <td>1</td>
      <td>0.0794</td>
      <td>160.083</td>
      <td>4.0</td>
      <td>0.588</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.0344</td>
      <td>0.838</td>
      <td>185707</td>
      <td>0.412</td>
      <td>0.000234</td>
      <td>2</td>
      <td>0.1590</td>
      <td>-7.148</td>
      <td>1</td>
      <td>0.2890</td>
      <td>75.044</td>
      <td>4.0</td>
      <td>0.173</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.6040</td>
      <td>0.494</td>
      <td>199413</td>
      <td>0.338</td>
      <td>0.510000</td>
      <td>5</td>
      <td>0.0922</td>
      <td>-15.236</td>
      <td>1</td>
      <td>0.0261</td>
      <td>86.468</td>
      <td>4.0</td>
      <td>0.230</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.1800</td>
      <td>0.678</td>
      <td>392893</td>
      <td>0.561</td>
      <td>0.512000</td>
      <td>5</td>
      <td>0.4390</td>
      <td>-11.648</td>
      <td>0</td>
      <td>0.0694</td>
      <td>174.004</td>
      <td>4.0</td>
      <td>0.904</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</section>
<section id="dimensions-in-ml-problems">
<h3>Dimensions in ML problems<a class="headerlink" href="#dimensions-in-ml-problems" title="Permalink to this headline">#</a></h3>
<p>In ML, usually we deal with high dimensional problems where examples are hard to visualize.</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(d \approx 20\)</span> is considered low dimensional</p></li>
<li><p><span class="math notranslate nohighlight">\(d \approx 1000\)</span> is considered medium dimensional</p></li>
<li><p><span class="math notranslate nohighlight">\(d \approx 100,000\)</span> is considered high dimensional</p></li>
</ul>
</section>
<section id="feature-vectors">
<h3>Feature vectors<a class="headerlink" href="#feature-vectors" title="Permalink to this headline">#</a></h3>
<dl class="simple myst">
<dt><strong>Feature vector</strong></dt><dd><p>is composed of feature values associated with an example.</p>
</dd>
</dl>
<p>Some example feature vectors are shown below.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span>
    <span class="s2">&quot;An example feature vector from the cities dataset: </span><span class="si">%s</span><span class="s2">&quot;</span>
    <span class="o">%</span> <span class="p">(</span><span class="n">X_cities</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">())</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span>
    <span class="s2">&quot;An example feature vector from the Spotify dataset: </span><span class="se">\n</span><span class="si">%s</span><span class="s2">&quot;</span>
    <span class="o">%</span> <span class="p">(</span><span class="n">X_spotify</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">())</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>An example feature vector from the cities dataset: [-130.0437   55.9773]
An example feature vector from the Spotify dataset: 
[ 1.02000e-02  8.33000e-01  2.04600e+05  4.34000e-01  2.19000e-02
  2.00000e+00  1.65000e-01 -8.79500e+00  1.00000e+00  4.31000e-01
  1.50062e+02  4.00000e+00  2.86000e-01]
</pre></div>
</div>
</div>
</div>
</section>
<section id="similarity-between-examples">
<h3>Similarity between examples<a class="headerlink" href="#similarity-between-examples" title="Permalink to this headline">#</a></h3>
<p>Let’s take 2 points (two feature vectors) from the cities dataset.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">two_cities</span> <span class="o">=</span> <span class="n">X_cities</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">120</span><span class="p">)</span>
<span class="n">two_cities</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>longitude</th>
      <th>latitude</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>69</th>
      <td>-104.8253</td>
      <td>38.8340</td>
    </tr>
    <tr>
      <th>35</th>
      <td>-112.0741</td>
      <td>33.4484</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>The two sampled points are shown as big black circles.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mglearn</span><span class="o">.</span><span class="n">discrete_scatter</span><span class="p">(</span>
    <span class="n">X_cities</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_cities</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">y_cities</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span>
<span class="p">)</span>
<span class="n">mglearn</span><span class="o">.</span><span class="n">discrete_scatter</span><span class="p">(</span>
    <span class="n">two_cities</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">two_cities</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">markers</span><span class="o">=</span><span class="s2">&quot;o&quot;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s2">&quot;k&quot;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">18</span>
<span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/04_kNNs-SVM-RBF_35_0.png" src="../_images/04_kNNs-SVM-RBF_35_0.png" />
</div>
</div>
</section>
<section id="distance-between-feature-vectors">
<h3>Distance between feature vectors<a class="headerlink" href="#distance-between-feature-vectors" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>For the cities at the two big circles, what is the <em>distance</em> between them?</p></li>
<li><p>A common way to calculate the distance between vectors is calculating the <strong>Euclidean distance</strong>.</p></li>
<li><p>The euclidean distance between vectors <span class="math notranslate nohighlight">\(u = &lt;u_1, u_2, \dots, u_n&gt;\)</span> and <span class="math notranslate nohighlight">\(v = &lt;v_1, v_2, \dots, v_n&gt;\)</span> is defined as:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[distance(u, v) = \sqrt{\sum_{i =1}^{n} (u_i - v_i)^2}\]</div>
</section>
<section id="euclidean-distance">
<h3>Euclidean distance<a class="headerlink" href="#euclidean-distance" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">two_cities</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>longitude</th>
      <th>latitude</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>69</th>
      <td>-104.8253</td>
      <td>38.8340</td>
    </tr>
    <tr>
      <th>35</th>
      <td>-112.0741</td>
      <td>33.4484</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<ul class="simple">
<li><p>Subtract the two cities</p></li>
<li><p>Square the difference</p></li>
<li><p>Sum them up</p></li>
<li><p>Take the square root</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Subtract the two cities</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Subtract the cities: </span><span class="se">\n</span><span class="si">%s</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">two_cities</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">two_cities</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>

<span class="c1"># Squared sum of the difference</span>
<span class="nb">print</span><span class="p">(</span>
    <span class="s2">&quot;Sum of squares: </span><span class="si">%0.4f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">two_cities</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">two_cities</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">**</span> <span class="mi">2</span><span class="p">))</span>
<span class="p">)</span>

<span class="c1"># Take the square root</span>
<span class="nb">print</span><span class="p">(</span>
    <span class="s2">&quot;Euclidean distance between cities: </span><span class="si">%0.4f</span><span class="s2">&quot;</span>
    <span class="o">%</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">two_cities</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">two_cities</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)))</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Subtract the cities: 
longitude   -7.2488
latitude    -5.3856
dtype: float64

Sum of squares: 81.5498
Euclidean distance between cities: 9.0305
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">two_cities</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>longitude</th>
      <th>latitude</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>69</th>
      <td>-104.8253</td>
      <td>38.8340</td>
    </tr>
    <tr>
      <th>35</th>
      <td>-112.0741</td>
      <td>33.4484</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Euclidean distance using sklearn</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics.pairwise</span> <span class="kn">import</span> <span class="n">euclidean_distances</span>

<span class="n">euclidean_distances</span><span class="p">(</span><span class="n">two_cities</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[0.        , 9.03049217],
       [9.03049217, 0.        ]])
</pre></div>
</div>
</div>
</div>
<p>Note: <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code> supports a number of other <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.DistanceMetric.html">distance metrics</a>.</p>
</section>
<section id="finding-the-nearest-neighbour">
<h3>Finding the nearest neighbour<a class="headerlink" href="#finding-the-nearest-neighbour" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>Let’s look at distances from all cities to all other cities</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dists</span> <span class="o">=</span> <span class="n">euclidean_distances</span><span class="p">(</span><span class="n">X_cities</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">fill_diagonal</span><span class="p">(</span><span class="n">dists</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">)</span>
<span class="n">dists</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(209, 209)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">dists</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
      <th>5</th>
      <th>6</th>
      <th>7</th>
      <th>8</th>
      <th>9</th>
      <th>...</th>
      <th>199</th>
      <th>200</th>
      <th>201</th>
      <th>202</th>
      <th>203</th>
      <th>204</th>
      <th>205</th>
      <th>206</th>
      <th>207</th>
      <th>208</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>inf</td>
      <td>4.955113</td>
      <td>9.869531</td>
      <td>10.106452</td>
      <td>10.449666</td>
      <td>19.381676</td>
      <td>28.366626</td>
      <td>33.283857</td>
      <td>33.572105</td>
      <td>36.180388</td>
      <td>...</td>
      <td>9.834455</td>
      <td>58.807684</td>
      <td>16.925593</td>
      <td>56.951696</td>
      <td>59.384127</td>
      <td>58.289799</td>
      <td>64.183423</td>
      <td>52.426410</td>
      <td>58.033459</td>
      <td>51.498562</td>
    </tr>
    <tr>
      <th>1</th>
      <td>4.955113</td>
      <td>inf</td>
      <td>14.677579</td>
      <td>14.935802</td>
      <td>15.305346</td>
      <td>24.308448</td>
      <td>33.200978</td>
      <td>38.082949</td>
      <td>38.359992</td>
      <td>40.957919</td>
      <td>...</td>
      <td>14.668787</td>
      <td>63.533498</td>
      <td>21.656349</td>
      <td>61.691640</td>
      <td>64.045304</td>
      <td>63.032656</td>
      <td>68.887343</td>
      <td>57.253724</td>
      <td>62.771969</td>
      <td>56.252160</td>
    </tr>
    <tr>
      <th>2</th>
      <td>9.869531</td>
      <td>14.677579</td>
      <td>inf</td>
      <td>0.334411</td>
      <td>0.808958</td>
      <td>11.115406</td>
      <td>20.528403</td>
      <td>25.525757</td>
      <td>25.873103</td>
      <td>28.479109</td>
      <td>...</td>
      <td>0.277381</td>
      <td>51.076798</td>
      <td>10.783789</td>
      <td>49.169693</td>
      <td>51.934205</td>
      <td>50.483751</td>
      <td>56.512897</td>
      <td>44.235152</td>
      <td>50.249720</td>
      <td>43.699224</td>
    </tr>
    <tr>
      <th>3</th>
      <td>10.106452</td>
      <td>14.935802</td>
      <td>0.334411</td>
      <td>inf</td>
      <td>0.474552</td>
      <td>10.781004</td>
      <td>20.194002</td>
      <td>25.191396</td>
      <td>25.538702</td>
      <td>28.144750</td>
      <td>...</td>
      <td>0.275352</td>
      <td>50.743133</td>
      <td>10.480249</td>
      <td>48.836189</td>
      <td>51.599860</td>
      <td>50.150395</td>
      <td>56.179123</td>
      <td>43.904226</td>
      <td>49.916254</td>
      <td>43.365623</td>
    </tr>
    <tr>
      <th>4</th>
      <td>10.449666</td>
      <td>15.305346</td>
      <td>0.808958</td>
      <td>0.474552</td>
      <td>inf</td>
      <td>10.306500</td>
      <td>19.719500</td>
      <td>24.716985</td>
      <td>25.064200</td>
      <td>27.670344</td>
      <td>...</td>
      <td>0.675814</td>
      <td>50.269880</td>
      <td>10.051472</td>
      <td>48.363192</td>
      <td>51.125476</td>
      <td>49.677629</td>
      <td>55.705696</td>
      <td>43.435186</td>
      <td>49.443317</td>
      <td>42.892477</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>204</th>
      <td>58.289799</td>
      <td>63.032656</td>
      <td>50.483751</td>
      <td>50.150395</td>
      <td>49.677629</td>
      <td>39.405415</td>
      <td>30.043890</td>
      <td>25.057003</td>
      <td>24.746328</td>
      <td>22.127878</td>
      <td>...</td>
      <td>50.333340</td>
      <td>0.873356</td>
      <td>41.380643</td>
      <td>1.345136</td>
      <td>3.373031</td>
      <td>inf</td>
      <td>6.102435</td>
      <td>6.957987</td>
      <td>0.316363</td>
      <td>6.800190</td>
    </tr>
    <tr>
      <th>205</th>
      <td>64.183423</td>
      <td>68.887343</td>
      <td>56.512897</td>
      <td>56.179123</td>
      <td>55.705696</td>
      <td>45.418031</td>
      <td>36.031385</td>
      <td>31.032874</td>
      <td>30.709185</td>
      <td>28.088948</td>
      <td>...</td>
      <td>56.358333</td>
      <td>5.442806</td>
      <td>47.259286</td>
      <td>7.369875</td>
      <td>5.108681</td>
      <td>6.102435</td>
      <td>inf</td>
      <td>12.950733</td>
      <td>6.303916</td>
      <td>12.819584</td>
    </tr>
    <tr>
      <th>206</th>
      <td>52.426410</td>
      <td>57.253724</td>
      <td>44.235152</td>
      <td>43.904226</td>
      <td>43.435186</td>
      <td>33.258427</td>
      <td>24.059863</td>
      <td>19.187663</td>
      <td>18.932124</td>
      <td>16.380495</td>
      <td>...</td>
      <td>44.100248</td>
      <td>7.767852</td>
      <td>35.637982</td>
      <td>5.930561</td>
      <td>9.731583</td>
      <td>6.957987</td>
      <td>12.950733</td>
      <td>inf</td>
      <td>6.837848</td>
      <td>3.322755</td>
    </tr>
    <tr>
      <th>207</th>
      <td>58.033459</td>
      <td>62.771969</td>
      <td>50.249720</td>
      <td>49.916254</td>
      <td>49.443317</td>
      <td>39.167214</td>
      <td>29.799983</td>
      <td>24.810368</td>
      <td>24.497386</td>
      <td>21.878183</td>
      <td>...</td>
      <td>50.098326</td>
      <td>0.930123</td>
      <td>41.121628</td>
      <td>1.082749</td>
      <td>3.286821</td>
      <td>0.316363</td>
      <td>6.303916</td>
      <td>6.837848</td>
      <td>inf</td>
      <td>6.555740</td>
    </tr>
    <tr>
      <th>208</th>
      <td>51.498562</td>
      <td>56.252160</td>
      <td>43.699224</td>
      <td>43.365623</td>
      <td>42.892477</td>
      <td>32.612755</td>
      <td>23.244592</td>
      <td>18.256813</td>
      <td>17.946783</td>
      <td>15.328953</td>
      <td>...</td>
      <td>43.546610</td>
      <td>7.378764</td>
      <td>34.596810</td>
      <td>5.473691</td>
      <td>8.568009</td>
      <td>6.800190</td>
      <td>12.819584</td>
      <td>3.322755</td>
      <td>6.555740</td>
      <td>inf</td>
    </tr>
  </tbody>
</table>
<p>209 rows × 209 columns</p>
</div></div></div>
</div>
<p>Let’s look at the distances between City 0 and some other cities.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Feature vector for city 0: </span><span class="se">\n</span><span class="si">%s</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">X_cities</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Distances from city 0 to the first 5 cities: </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">dists</span><span class="p">[</span><span class="mi">0</span><span class="p">][:</span><span class="mi">5</span><span class="p">]))</span>
<span class="c1"># We can find the closest city with `np.argmin`:</span>
<span class="nb">print</span><span class="p">(</span>
    <span class="s2">&quot;The closest city from city 0 is: </span><span class="si">%d</span><span class="s2"> </span><span class="se">\n\n</span><span class="s2">with feature vector: </span><span class="se">\n</span><span class="si">%s</span><span class="s2">&quot;</span>
    <span class="o">%</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">dists</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">X_cities</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">dists</span><span class="p">[</span><span class="mi">0</span><span class="p">])])</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Feature vector for city 0: 
longitude   -130.0437
latitude      55.9773
Name: 0, dtype: float64

Distances from city 0 to the first 5 cities: [        inf  4.95511263  9.869531   10.10645223 10.44966612]
The closest city from city 0 is: 81 

with feature vector: 
longitude   -129.9912
latitude      55.9383
Name: 81, dtype: float64
</pre></div>
</div>
</div>
</div>
<p>Ok, so the closest city to City 0 is City 81.</p>
</section>
<section id="question">
<h3>Question<a class="headerlink" href="#question" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>Why did we set the diagonal entries to infinity before finding the closest city?</p></li>
</ul>
</section>
<section id="finding-the-distances-to-a-query-point">
<h3>Finding the distances to a query point<a class="headerlink" href="#finding-the-distances-to-a-query-point" title="Permalink to this headline">#</a></h3>
<p>We can also find the distances to a new “test” or “query” city:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Let&#39;s find a city that&#39;s closest to the a query city</span>
<span class="n">query_point</span> <span class="o">=</span> <span class="p">[[</span><span class="o">-</span><span class="mi">80</span><span class="p">,</span> <span class="mi">25</span><span class="p">]]</span>

<span class="n">dists</span> <span class="o">=</span> <span class="n">euclidean_distances</span><span class="p">(</span><span class="n">X_cities</span><span class="p">,</span> <span class="n">query_point</span><span class="p">)</span>
<span class="n">dists</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">10</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[58.85545875],
       [63.80062924],
       [49.30530902],
       [49.01473536],
       [48.60495488],
       [39.96834506],
       [32.92852376],
       [29.53520104],
       [29.52881619],
       [27.84679073]])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># The query point is closest to</span>
<span class="nb">print</span><span class="p">(</span>
    <span class="s2">&quot;The query point </span><span class="si">%s</span><span class="s2"> is closest to the city with index </span><span class="si">%d</span><span class="s2"> and the distance between them is: </span><span class="si">%0.4f</span><span class="s2">&quot;</span>
    <span class="o">%</span> <span class="p">(</span><span class="n">query_point</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">dists</span><span class="p">),</span> <span class="n">dists</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">dists</span><span class="p">)])</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>The query point [[-80, 25]] is closest to the city with index 72 and the distance between them is: 0.7982
</pre></div>
</div>
</div>
</div>
<p><br><br></p>
</section>
</section>
<section id="k-nearest-neighbours-k-nns-video">
<h2><span class="math notranslate nohighlight">\(k\)</span>-Nearest Neighbours (<span class="math notranslate nohighlight">\(k\)</span>-NNs) [<a class="reference external" href="https://youtu.be/bENDqXKJLmg">video</a>]<a class="headerlink" href="#k-nearest-neighbours-k-nns-video" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">small_cities</span> <span class="o">=</span> <span class="n">cities_df</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">90</span><span class="p">)</span>
<span class="n">one_city</span> <span class="o">=</span> <span class="n">small_cities</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">44</span><span class="p">)</span>
<span class="n">small_train_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">small_cities</span><span class="p">,</span> <span class="n">one_city</span><span class="p">])</span><span class="o">.</span><span class="n">drop_duplicates</span><span class="p">(</span><span class="n">keep</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_small_cities</span> <span class="o">=</span> <span class="n">small_train_df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;country&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
<span class="n">y_small_cities</span> <span class="o">=</span> <span class="n">small_train_df</span><span class="p">[</span><span class="s2">&quot;country&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
<span class="n">test_point</span> <span class="o">=</span> <span class="n">one_city</span><span class="p">[[</span><span class="s2">&quot;longitude&quot;</span><span class="p">,</span> <span class="s2">&quot;latitude&quot;</span><span class="p">]]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_train_test_points</span><span class="p">(</span>
    <span class="n">X_small_cities</span><span class="p">,</span>
    <span class="n">y_small_cities</span><span class="p">,</span>
    <span class="n">test_point</span><span class="p">,</span>
    <span class="n">class_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Canada&quot;</span><span class="p">,</span> <span class="s2">&quot;USA&quot;</span><span class="p">],</span>
    <span class="n">test_format</span><span class="o">=</span><span class="s2">&quot;circle&quot;</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/04_kNNs-SVM-RBF_58_0.png" src="../_images/04_kNNs-SVM-RBF_58_0.png" />
</div>
</div>
<ul class="simple">
<li><p>Given a new data point, predict the class of the data point by finding the “closest” data point in the training set, i.e., by finding its “nearest neighbour” or majority vote of nearest neighbours.</p></li>
</ul>
<p>Suppose we want to predict the class of the black point.</p>
<ul class="simple">
<li><p>An intuitive way to do this is predict the same label as the “closest” point (<span class="math notranslate nohighlight">\(k = 1\)</span>) (1-nearest neighbour)</p></li>
<li><p>We would predict a target of <strong>USA</strong> in this case.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_knn_clf</span><span class="p">(</span>
    <span class="n">X_small_cities</span><span class="p">,</span>
    <span class="n">y_small_cities</span><span class="p">,</span>
    <span class="n">test_point</span><span class="p">,</span>
    <span class="n">n_neighbors</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">class_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Canada&quot;</span><span class="p">,</span> <span class="s2">&quot;USA&quot;</span><span class="p">],</span>
    <span class="n">test_format</span><span class="o">=</span><span class="s2">&quot;circle&quot;</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>n_neighbors 1
</pre></div>
</div>
<img alt="../_images/04_kNNs-SVM-RBF_61_1.png" src="../_images/04_kNNs-SVM-RBF_61_1.png" />
</div>
</div>
<p>How about using <span class="math notranslate nohighlight">\(k &gt; 1\)</span> to get a more robust estimate?</p>
<ul class="simple">
<li><p>For example, we could also use the 3 closest points (<em>k</em> = 3) and let them <strong>vote</strong> on the correct class.</p></li>
<li><p>The <strong>Canada</strong> class would win in this case.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_knn_clf</span><span class="p">(</span>
    <span class="n">X_small_cities</span><span class="p">,</span>
    <span class="n">y_small_cities</span><span class="p">,</span>
    <span class="n">test_point</span><span class="p">,</span>
    <span class="n">n_neighbors</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
    <span class="n">class_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Canada&quot;</span><span class="p">,</span> <span class="s2">&quot;USA&quot;</span><span class="p">],</span>
    <span class="n">test_format</span><span class="o">=</span><span class="s2">&quot;circle&quot;</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>n_neighbors 3
</pre></div>
</div>
<img alt="../_images/04_kNNs-SVM-RBF_63_1.png" src="../_images/04_kNNs-SVM-RBF_63_1.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>

<span class="n">k_values</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>

<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">k_values</span><span class="p">:</span>
    <span class="n">neigh</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="n">k</span><span class="p">)</span>
    <span class="n">neigh</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_small_cities</span><span class="p">,</span> <span class="n">y_small_cities</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span>
        <span class="s2">&quot;Prediction of the black dot with </span><span class="si">%d</span><span class="s2"> neighbours: </span><span class="si">%s</span><span class="s2">&quot;</span>
        <span class="o">%</span> <span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">neigh</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_point</span><span class="p">))</span>
    <span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Prediction of the black dot with 1 neighbours: [&#39;USA&#39;]
Prediction of the black dot with 3 neighbours: [&#39;Canada&#39;]
</pre></div>
</div>
</div>
</div>
<section id="choosing-n-neighbors">
<h3>Choosing <code class="docutils literal notranslate"><span class="pre">n_neighbors</span></code><a class="headerlink" href="#choosing-n-neighbors" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>The primary hyperparameter of the model is <code class="docutils literal notranslate"><span class="pre">n_neighbors</span></code> (<span class="math notranslate nohighlight">\(k\)</span>) which decides how many neighbours should vote during prediction?</p></li>
<li><p>What happens when we play around with <code class="docutils literal notranslate"><span class="pre">n_neighbors</span></code>?</p></li>
<li><p>Are we more likely to overfit with a low <code class="docutils literal notranslate"><span class="pre">n_neighbors</span></code> or a high <code class="docutils literal notranslate"><span class="pre">n_neighbors</span></code>?</p></li>
<li><p>Let’s examine the effect of the hyperparameter on our cities data.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">cities_df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;country&quot;</span><span class="p">])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">cities_df</span><span class="p">[</span><span class="s2">&quot;country&quot;</span><span class="p">]</span>

<span class="c1"># split into train and test sets</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">123</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">k</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">knn1</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="n">k</span><span class="p">)</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_validate</span><span class="p">(</span><span class="n">knn1</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>fit_time</th>
      <th>score_time</th>
      <th>test_score</th>
      <th>train_score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.000821</td>
      <td>0.001385</td>
      <td>0.710526</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.000541</td>
      <td>0.000817</td>
      <td>0.684211</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.000511</td>
      <td>0.000796</td>
      <td>0.842105</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.000507</td>
      <td>0.000788</td>
      <td>0.702703</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.000501</td>
      <td>0.000786</td>
      <td>0.837838</td>
      <td>1.0</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">k</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">knn100</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="n">k</span><span class="p">)</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_validate</span><span class="p">(</span><span class="n">knn100</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>fit_time</th>
      <th>score_time</th>
      <th>test_score</th>
      <th>train_score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.000611</td>
      <td>0.035535</td>
      <td>0.605263</td>
      <td>0.600000</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.000516</td>
      <td>0.001087</td>
      <td>0.605263</td>
      <td>0.600000</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.000500</td>
      <td>0.001072</td>
      <td>0.605263</td>
      <td>0.600000</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.000499</td>
      <td>0.001049</td>
      <td>0.594595</td>
      <td>0.602649</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.000495</td>
      <td>0.001037</td>
      <td>0.594595</td>
      <td>0.602649</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">results</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">knn</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="n">n_neighbors</span><span class="p">)</span>
    <span class="n">scores</span> <span class="o">=</span> <span class="n">cross_validate</span><span class="p">(</span><span class="n">knn</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">results</span><span class="p">[</span><span class="s2">&quot;n_neighbours&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">n_neighbors</span><span class="p">]</span>
    <span class="n">results</span><span class="p">[</span><span class="s2">&quot;mean_train_score&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="nb">round</span><span class="p">(</span><span class="n">scores</span><span class="p">[</span><span class="s2">&quot;train_score&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="mi">3</span><span class="p">)]</span>
    <span class="n">results</span><span class="p">[</span><span class="s2">&quot;mean_valid_score&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="nb">round</span><span class="p">(</span><span class="n">scores</span><span class="p">[</span><span class="s2">&quot;test_score&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="mi">3</span><span class="p">)]</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">results</span><span class="p">))</span>


<span class="n">interactive</span><span class="p">(</span>
    <span class="n">f</span><span class="p">,</span>
    <span class="n">n_neighbors</span><span class="o">=</span><span class="n">widgets</span><span class="o">.</span><span class="n">IntSlider</span><span class="p">(</span><span class="nb">min</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">101</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "5faf5e1e842349e3b27ae2b53353222d"}
</script></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_knn_decision_boundaries</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">k_values</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span> <span class="mi">100</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/04_kNNs-SVM-RBF_71_0.png" src="../_images/04_kNNs-SVM-RBF_71_0.png" />
</div>
</div>
</section>
<section id="how-to-choose-n-neighbors">
<h3>How to choose <code class="docutils literal notranslate"><span class="pre">n_neighbors</span></code>?<a class="headerlink" href="#how-to-choose-n-neighbors" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">n_neighbors</span></code> is a hyperparameter</p></li>
<li><p>We can use hyperparameter optimization to choose <code class="docutils literal notranslate"><span class="pre">n_neighbors</span></code>.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">results_dict</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;n_neighbors&quot;</span><span class="p">:</span> <span class="p">[],</span>
    <span class="s2">&quot;mean_train_score&quot;</span><span class="p">:</span> <span class="p">[],</span>
    <span class="s2">&quot;mean_cv_score&quot;</span><span class="p">:</span> <span class="p">[],</span>
    <span class="s2">&quot;std_cv_score&quot;</span><span class="p">:</span> <span class="p">[],</span>
    <span class="s2">&quot;std_train_score&quot;</span><span class="p">:</span> <span class="p">[],</span>
<span class="p">}</span>
<span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;n_neighbors&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">5</span><span class="p">)}</span>

<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">param_grid</span><span class="p">[</span><span class="s2">&quot;n_neighbors&quot;</span><span class="p">]:</span>
    <span class="n">knn</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="n">k</span><span class="p">)</span>
    <span class="n">scores</span> <span class="o">=</span> <span class="n">cross_validate</span><span class="p">(</span><span class="n">knn</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">results_dict</span><span class="p">[</span><span class="s2">&quot;n_neighbors&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>

    <span class="n">results_dict</span><span class="p">[</span><span class="s2">&quot;mean_cv_score&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">scores</span><span class="p">[</span><span class="s2">&quot;test_score&quot;</span><span class="p">]))</span>
    <span class="n">results_dict</span><span class="p">[</span><span class="s2">&quot;mean_train_score&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">scores</span><span class="p">[</span><span class="s2">&quot;train_score&quot;</span><span class="p">]))</span>
    <span class="n">results_dict</span><span class="p">[</span><span class="s2">&quot;std_cv_score&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">scores</span><span class="p">[</span><span class="s2">&quot;test_score&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">std</span><span class="p">())</span>
    <span class="n">results_dict</span><span class="p">[</span><span class="s2">&quot;std_train_score&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">scores</span><span class="p">[</span><span class="s2">&quot;train_score&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">std</span><span class="p">())</span>

<span class="n">results_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">results_dict</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">results_df</span> <span class="o">=</span> <span class="n">results_df</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="s2">&quot;n_neighbors&quot;</span><span class="p">)</span>
<span class="n">results_df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>mean_train_score</th>
      <th>mean_cv_score</th>
      <th>std_cv_score</th>
      <th>std_train_score</th>
    </tr>
    <tr>
      <th>n_neighbors</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>1.000000</td>
      <td>0.755477</td>
      <td>0.069530</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>6</th>
      <td>0.831135</td>
      <td>0.792603</td>
      <td>0.046020</td>
      <td>0.013433</td>
    </tr>
    <tr>
      <th>11</th>
      <td>0.819152</td>
      <td>0.802987</td>
      <td>0.041129</td>
      <td>0.011336</td>
    </tr>
    <tr>
      <th>16</th>
      <td>0.801863</td>
      <td>0.782219</td>
      <td>0.074141</td>
      <td>0.008735</td>
    </tr>
    <tr>
      <th>21</th>
      <td>0.777934</td>
      <td>0.766430</td>
      <td>0.062792</td>
      <td>0.016944</td>
    </tr>
    <tr>
      <th>26</th>
      <td>0.755364</td>
      <td>0.723613</td>
      <td>0.061937</td>
      <td>0.025910</td>
    </tr>
    <tr>
      <th>31</th>
      <td>0.743391</td>
      <td>0.707681</td>
      <td>0.057646</td>
      <td>0.030408</td>
    </tr>
    <tr>
      <th>36</th>
      <td>0.728777</td>
      <td>0.707681</td>
      <td>0.064452</td>
      <td>0.021305</td>
    </tr>
    <tr>
      <th>41</th>
      <td>0.706128</td>
      <td>0.681223</td>
      <td>0.061241</td>
      <td>0.018310</td>
    </tr>
    <tr>
      <th>46</th>
      <td>0.694155</td>
      <td>0.660171</td>
      <td>0.093390</td>
      <td>0.018178</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">results_df</span><span class="p">[[</span><span class="s2">&quot;mean_train_score&quot;</span><span class="p">,</span> <span class="s2">&quot;mean_cv_score&quot;</span><span class="p">]]</span><span class="o">.</span><span class="n">plot</span><span class="p">();</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/04_kNNs-SVM-RBF_75_0.png" src="../_images/04_kNNs-SVM-RBF_75_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">best_n_neighbours</span> <span class="o">=</span> <span class="n">results_df</span><span class="o">.</span><span class="n">idxmax</span><span class="p">()[</span><span class="s2">&quot;mean_cv_score&quot;</span><span class="p">]</span>
<span class="n">best_n_neighbours</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>11
</pre></div>
</div>
</div>
</div>
<p>Let’s try our best model on test data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">knn</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="n">best_n_neighbours</span><span class="p">)</span>
<span class="n">knn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test accuracy: </span><span class="si">%0.3f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">knn</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Test accuracy: 0.905
</pre></div>
</div>
</div>
</div>
<p>Seems like we got lucky with the test set here.</p>
<p><br><br></p>
</section>
</section>
<section id="questions-for-you">
<h2>❓❓ Questions for you<a class="headerlink" href="#questions-for-you" title="Permalink to this headline">#</a></h2>
<section id="iclicker-exercise-4-1">
<h3>(iClicker) Exercise 4.1<a class="headerlink" href="#iclicker-exercise-4-1" title="Permalink to this headline">#</a></h3>
<p><strong>iClicker cloud join link: https://join.iclicker.com/3DP5H</strong></p>
<p><strong>Select all of the following statements which are TRUE.</strong></p>
<ol class="simple">
<li><p>Analogy-based models find examples from the test set that are most similar to the query example we are predicting.</p></li>
<li><p>Euclidean distance will always have a non-negative value.</p></li>
<li><p>With <span class="math notranslate nohighlight">\(k\)</span>-NN, setting the hyperparameter <span class="math notranslate nohighlight">\(k\)</span> to larger values typically reduces training error.</p></li>
<li><p>Similar to decision trees, <span class="math notranslate nohighlight">\(k\)</span>-NNs finds a small set of good features.</p></li>
<li><p>In <span class="math notranslate nohighlight">\(k\)</span>-NN, with <span class="math notranslate nohighlight">\(k &gt; 1\)</span>, the classification of the closest neighbour to the test example always contributes the most to the prediction.</p></li>
</ol>
</section>
</section>
<section id="break-5-min">
<h2>Break (5 min)<a class="headerlink" href="#break-5-min" title="Permalink to this headline">#</a></h2>
<p><img alt="" src="../_images/eva-coffee.png" /></p>
<p><br><br></p>
</section>
<section id="more-on-k-nns-video">
<h2>More on <span class="math notranslate nohighlight">\(k\)</span>-NNs [<a class="reference external" href="https://youtu.be/IRGbqi5S9gQ">video</a>]<a class="headerlink" href="#more-on-k-nns-video" title="Permalink to this headline">#</a></h2>
<section id="other-useful-arguments-of-kneighborsclassifier">
<h3>Other useful arguments of <code class="docutils literal notranslate"><span class="pre">KNeighborsClassifier</span></code><a class="headerlink" href="#other-useful-arguments-of-kneighborsclassifier" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">weights</span></code> <span class="math notranslate nohighlight">\(\rightarrow\)</span> When predicting label, you can assign higher weight to the examples which are closer to the query example.</p></li>
<li><p>Exercise for you: Play around with this argument. Do you get a better validation score?</p></li>
</ul>
</section>
<section id="regression-with-k-nearest-neighbours-k-nns">
<h3>Regression with <span class="math notranslate nohighlight">\(k\)</span>-nearest neighbours (<span class="math notranslate nohighlight">\(k\)</span>-NNs)<a class="headerlink" href="#regression-with-k-nearest-neighbours-k-nns" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>Can we solve regression problems with <span class="math notranslate nohighlight">\(k\)</span>-nearest neighbours algorithm?</p></li>
<li><p>In <span class="math notranslate nohighlight">\(k\)</span>-NN regression we take the average of the <span class="math notranslate nohighlight">\(k\)</span>-nearest neighbours.</p></li>
<li><p>We can also have weighted regression.</p></li>
</ul>
<p>See an example of regression in the lecture notes.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mglearn</span><span class="o">.</span><span class="n">plots</span><span class="o">.</span><span class="n">plot_knn_regression</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/04_kNNs-SVM-RBF_88_0.png" src="../_images/04_kNNs-SVM-RBF_88_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mglearn</span><span class="o">.</span><span class="n">plots</span><span class="o">.</span><span class="n">plot_knn_regression</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/04_kNNs-SVM-RBF_89_0.png" src="../_images/04_kNNs-SVM-RBF_89_0.png" />
</div>
</div>
</section>
<section id="pros-of-k-nns-for-supervised-learning">
<h3>Pros of <span class="math notranslate nohighlight">\(k\)</span>-NNs for supervised learning<a class="headerlink" href="#pros-of-k-nns-for-supervised-learning" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>Easy to understand, interpret.</p></li>
<li><p>Simple hyperparameter <span class="math notranslate nohighlight">\(k\)</span> (<code class="docutils literal notranslate"><span class="pre">n_neighbors</span></code>) controlling the fundamental tradeoff.</p></li>
<li><p>Can learn very complex functions given enough data.</p></li>
<li><p>Lazy learning: Takes no time to <code class="docutils literal notranslate"><span class="pre">fit</span></code></p></li>
</ul>
</section>
<section id="cons-of-k-nns-for-supervised-learning">
<h3>Cons of <span class="math notranslate nohighlight">\(k\)</span>-NNs for supervised learning<a class="headerlink" href="#cons-of-k-nns-for-supervised-learning" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>Can be potentially be VERY slow during prediction time, especially when the training set is very large.</p></li>
<li><p>Often not that great test accuracy compared to the modern approaches.</p></li>
<li><p>It does not work well on datasets with many features or where most feature values are 0 most of the time (sparse datasets).</p></li>
</ul>
<div class="important admonition">
<p class="admonition-title">Attention</p>
<p>For regular <span class="math notranslate nohighlight">\(k\)</span>-NN for supervised learning (not with sparse matrices), you should scale your features. We’ll be looking into it soon.</p>
</div>
</section>
<section id="parametric-vs-non-parametric">
<h3>Parametric vs non parametric<a class="headerlink" href="#parametric-vs-non-parametric" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>You might see a lot of definitions of these terms.</p></li>
<li><p>A simple way to think about this is:</p>
<ul>
<li><p>do you need to store at least <span class="math notranslate nohighlight">\(O(n)\)</span> worth of stuff to make predictions? If so, it’s non-parametric.</p></li>
</ul>
</li>
<li><p>Non-parametric example: <span class="math notranslate nohighlight">\(k\)</span>-NN is a classic example of non-parametric models.</p></li>
<li><p>Parametric example: decision stump</p></li>
<li><p>If you want to know more about this, find some reading material <a class="reference external" href="https://www.cs.ubc.ca/~schmidtm/Courses/340-F16/L6.pdf">here</a>, <a class="reference external" href="http://mlss.tuebingen.mpg.de/2015/slides/ghahramani/gp-neural-nets15.pdf">here</a>, and <a class="reference external" href="https://machinelearningmastery.com/parametric-and-nonparametric-machine-learning-algorithms/">here</a>.</p></li>
<li><p>By the way, the terms “parametric” and “non-paramteric” are often used differently by statisticians, see <a class="reference external" href="https://help.xlstat.com/s/article/what-is-the-difference-between-a-parametric-and-a-nonparametric-test?language=en_US">here</a> for more…</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><span class="math notranslate nohighlight">\(\mathcal{O}(n)\)</span> is referred to as big <span class="math notranslate nohighlight">\(\mathcal{O}\)</span> notation. It tells you how fast an algorithm is or how much storage space it requires. For example, in simple terms, if you have <span class="math notranslate nohighlight">\(n\)</span> examples and you need to store them all you can say that the algorithm requires <span class="math notranslate nohighlight">\(\mathcal{O}(n)\)</span> worth of stuff.</p>
</div>
</section>
<section id="curse-of-dimensionality">
<h3>Curse of dimensionality<a class="headerlink" href="#curse-of-dimensionality" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>Affects all learners but especially bad for nearest-neighbour.</p></li>
<li><p><span class="math notranslate nohighlight">\(k\)</span>-NN usually works well when the number of dimensions <span class="math notranslate nohighlight">\(d\)</span> is small but things fall apart quickly as <span class="math notranslate nohighlight">\(d\)</span> goes up.</p></li>
<li><p>If there are many irrelevant attributes, <span class="math notranslate nohighlight">\(k\)</span>-NN is hopelessly confused because all of them contribute to finding similarity between examples.</p></li>
<li><p>With enough irrelevant attributes the accidental similarity swamps out meaningful similarity and <span class="math notranslate nohighlight">\(k\)</span>-NN is no better than random guessing.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_classification</span>

<span class="n">nfeats_accuracy</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;nfeats&quot;</span><span class="p">:</span> <span class="p">[],</span> <span class="s2">&quot;dummy_valid_accuracy&quot;</span><span class="p">:</span> <span class="p">[],</span> <span class="s2">&quot;KNN_valid_accuracy&quot;</span><span class="p">:</span> <span class="p">[]}</span>
<span class="k">for</span> <span class="n">n_feats</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2000</span><span class="p">,</span> <span class="mi">100</span><span class="p">):</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_classification</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">2000</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="n">n_feats</span><span class="p">,</span> <span class="n">n_classes</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
        <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">123</span>
    <span class="p">)</span>
    <span class="n">dummy</span> <span class="o">=</span> <span class="n">DummyClassifier</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s2">&quot;most_frequent&quot;</span><span class="p">)</span>
    <span class="n">dummy_scores</span> <span class="o">=</span> <span class="n">cross_validate</span><span class="p">(</span><span class="n">dummy</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="n">knn</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">()</span>
    <span class="n">scores</span> <span class="o">=</span> <span class="n">cross_validate</span><span class="p">(</span><span class="n">knn</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">nfeats_accuracy</span><span class="p">[</span><span class="s2">&quot;nfeats&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">n_feats</span><span class="p">)</span>
    <span class="n">nfeats_accuracy</span><span class="p">[</span><span class="s2">&quot;KNN_valid_accuracy&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">scores</span><span class="p">[</span><span class="s2">&quot;test_score&quot;</span><span class="p">]))</span>
    <span class="n">nfeats_accuracy</span><span class="p">[</span><span class="s2">&quot;dummy_valid_accuracy&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dummy_scores</span><span class="p">[</span><span class="s2">&quot;test_score&quot;</span><span class="p">]))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">nfeats_accuracy</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>nfeats</th>
      <th>dummy_valid_accuracy</th>
      <th>KNN_valid_accuracy</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>4</td>
      <td>0.503125</td>
      <td>0.965625</td>
    </tr>
    <tr>
      <th>1</th>
      <td>104</td>
      <td>0.504375</td>
      <td>0.816875</td>
    </tr>
    <tr>
      <th>2</th>
      <td>204</td>
      <td>0.503125</td>
      <td>0.646875</td>
    </tr>
    <tr>
      <th>3</th>
      <td>304</td>
      <td>0.503125</td>
      <td>0.681875</td>
    </tr>
    <tr>
      <th>4</th>
      <td>404</td>
      <td>0.503750</td>
      <td>0.606250</td>
    </tr>
    <tr>
      <th>5</th>
      <td>504</td>
      <td>0.505625</td>
      <td>0.629375</td>
    </tr>
    <tr>
      <th>6</th>
      <td>604</td>
      <td>0.502500</td>
      <td>0.651250</td>
    </tr>
    <tr>
      <th>7</th>
      <td>704</td>
      <td>0.501250</td>
      <td>0.618125</td>
    </tr>
    <tr>
      <th>8</th>
      <td>804</td>
      <td>0.501875</td>
      <td>0.651250</td>
    </tr>
    <tr>
      <th>9</th>
      <td>904</td>
      <td>0.508750</td>
      <td>0.590000</td>
    </tr>
    <tr>
      <th>10</th>
      <td>1004</td>
      <td>0.500625</td>
      <td>0.636250</td>
    </tr>
    <tr>
      <th>11</th>
      <td>1104</td>
      <td>0.506250</td>
      <td>0.630000</td>
    </tr>
    <tr>
      <th>12</th>
      <td>1204</td>
      <td>0.499375</td>
      <td>0.637500</td>
    </tr>
    <tr>
      <th>13</th>
      <td>1304</td>
      <td>0.503750</td>
      <td>0.604375</td>
    </tr>
    <tr>
      <th>14</th>
      <td>1404</td>
      <td>0.510000</td>
      <td>0.596250</td>
    </tr>
    <tr>
      <th>15</th>
      <td>1504</td>
      <td>0.500000</td>
      <td>0.573750</td>
    </tr>
    <tr>
      <th>16</th>
      <td>1604</td>
      <td>0.508750</td>
      <td>0.542500</td>
    </tr>
    <tr>
      <th>17</th>
      <td>1704</td>
      <td>0.503125</td>
      <td>0.591875</td>
    </tr>
    <tr>
      <th>18</th>
      <td>1804</td>
      <td>0.500000</td>
      <td>0.555625</td>
    </tr>
    <tr>
      <th>19</th>
      <td>1904</td>
      <td>0.505625</td>
      <td>0.568125</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p><br><br></p>
</section>
</section>
<section id="support-vector-machines-svms-with-rbf-kernel-video">
<h2>Support Vector Machines (SVMs) with RBF kernel [<a class="reference external" href="https://youtu.be/ic_zqOhi020">video</a>]<a class="headerlink" href="#support-vector-machines-svms-with-rbf-kernel-video" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p>Very high-level overview</p></li>
<li><p>Our goals here are</p>
<ul>
<li><p>Use <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code>’s SVM model.</p></li>
<li><p>Broadly explain the notion of support vectors.</p></li>
<li><p>Broadly explain the similarities and differences between <span class="math notranslate nohighlight">\(k\)</span>-NNs and SVM RBFs.</p></li>
<li><p>Explain how <code class="docutils literal notranslate"><span class="pre">C</span></code> and <code class="docutils literal notranslate"><span class="pre">gamma</span></code> hyperparameters control the fundamental tradeoff.</p></li>
</ul>
</li>
</ul>
<blockquote>
<div><p>(Optional) RBF stands for radial basis functions. We won’t go into what it means in this video. Refer to <a class="reference external" href="https://www.youtube.com/watch?v=Qc5IyLW_hns">this video</a> if you want to know more.</p>
</div></blockquote>
<section id="overview">
<h3>Overview<a class="headerlink" href="#overview" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>Another popular similarity-based algorithm is Support Vector Machines with RBF Kernel (SVM RBFs)</p></li>
<li><p>Superficially, SVM RBFs are more like weighted <span class="math notranslate nohighlight">\(k\)</span>-NNs.</p>
<ul>
<li><p>The decision boundary is defined by <strong>a set of positive and negative examples</strong> and <strong>their weights</strong> together with <strong>their similarity measure</strong>.</p></li>
<li><p>A test example is labeled positive if on average it looks more like positive examples than the negative examples.</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>The primary difference between <span class="math notranslate nohighlight">\(k\)</span>-NNs and SVM RBFs is that</p>
<ul>
<li><p>Unlike <span class="math notranslate nohighlight">\(k\)</span>-NNs, SVM RBFs only remember the key examples (support vectors).</p></li>
<li><p>SVMs use a different similarity metric which is called a “kernel”. A popular kernel is Radial Basis Functions (RBFs)</p></li>
<li><p>They usually perform better than <span class="math notranslate nohighlight">\(k\)</span>-NNs!</p></li>
</ul>
</li>
</ul>
</section>
<section id="let-s-explore-svm-rbfs">
<h3>Let’s explore SVM RBFs<a class="headerlink" href="#let-s-explore-svm-rbfs" title="Permalink to this headline">#</a></h3>
<p>Let’s try SVMs on the cities dataset.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mglearn</span><span class="o">.</span><span class="n">discrete_scatter</span><span class="p">(</span><span class="n">X_cities</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_cities</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">y_cities</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;longitude&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;latitude&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">1</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/04_kNNs-SVM-RBF_103_0.png" src="../_images/04_kNNs-SVM-RBF_103_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X_cities</span><span class="p">,</span> <span class="n">y_cities</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">123</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">knn</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="n">best_n_neighbours</span><span class="p">)</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_validate</span><span class="p">(</span><span class="n">knn</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Mean validation score </span><span class="si">%0.3f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">scores</span><span class="p">[</span><span class="s2">&quot;test_score&quot;</span><span class="p">])))</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Mean validation score 0.803
</pre></div>
</div>
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>fit_time</th>
      <th>score_time</th>
      <th>test_score</th>
      <th>train_score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.000707</td>
      <td>0.001222</td>
      <td>0.794118</td>
      <td>0.819549</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.000503</td>
      <td>0.000785</td>
      <td>0.764706</td>
      <td>0.819549</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.000493</td>
      <td>0.000774</td>
      <td>0.727273</td>
      <td>0.850746</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.000492</td>
      <td>0.000756</td>
      <td>0.787879</td>
      <td>0.828358</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.000478</td>
      <td>0.000751</td>
      <td>0.939394</td>
      <td>0.783582</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>

<span class="n">svm</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">(</span><span class="n">gamma</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>  <span class="c1"># Ignore gamma for now</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_validate</span><span class="p">(</span><span class="n">svm</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Mean validation score </span><span class="si">%0.3f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">scores</span><span class="p">[</span><span class="s2">&quot;test_score&quot;</span><span class="p">])))</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Mean validation score 0.820
</pre></div>
</div>
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>fit_time</th>
      <th>score_time</th>
      <th>test_score</th>
      <th>train_score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.001531</td>
      <td>0.000468</td>
      <td>0.823529</td>
      <td>0.842105</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.000701</td>
      <td>0.000432</td>
      <td>0.823529</td>
      <td>0.842105</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.000655</td>
      <td>0.000419</td>
      <td>0.727273</td>
      <td>0.858209</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.000659</td>
      <td>0.000419</td>
      <td>0.787879</td>
      <td>0.843284</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.000661</td>
      <td>0.000421</td>
      <td>0.939394</td>
      <td>0.805970</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</section>
<section id="decision-boundary-of-svms">
<h3>Decision boundary of SVMs<a class="headerlink" href="#decision-boundary-of-svms" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>We can think of SVM with RBF kernel as “smooth KNN”.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>

<span class="k">for</span> <span class="n">clf</span><span class="p">,</span> <span class="n">ax</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">([</span><span class="n">knn</span><span class="p">,</span> <span class="n">svm</span><span class="p">],</span> <span class="n">axes</span><span class="p">):</span>
    <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">mglearn</span><span class="o">.</span><span class="n">plots</span><span class="o">.</span><span class="n">plot_2d_separator</span><span class="p">(</span>
        <span class="n">clf</span><span class="p">,</span> <span class="n">X_train</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(),</span> <span class="n">fill</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.4</span>
    <span class="p">)</span>
    <span class="n">mglearn</span><span class="o">.</span><span class="n">discrete_scatter</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_train</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">clf</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;longitude&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;latitude&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/04_kNNs-SVM-RBF_108_0.png" src="../_images/04_kNNs-SVM-RBF_108_0.png" />
</div>
</div>
</section>
<section id="support-vectors">
<h3>Support vectors<a class="headerlink" href="#support-vectors" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>Each training example either is or isn’t a “support vector”.</p>
<ul>
<li><p>This gets decided during <code class="docutils literal notranslate"><span class="pre">fit</span></code>.</p></li>
</ul>
</li>
<li><p><strong>Main insight: the decision boundary only depends on the support vectors.</strong></p></li>
<li><p>Let’s look at the support vectors.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_blobs</span>

<span class="n">n</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">n_classes</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">X_toy</span><span class="p">,</span> <span class="n">y_toy</span> <span class="o">=</span> <span class="n">make_blobs</span><span class="p">(</span>
    <span class="n">n_samples</span><span class="o">=</span><span class="n">n</span><span class="p">,</span> <span class="n">centers</span><span class="o">=</span><span class="n">n_classes</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">300</span>
<span class="p">)</span>  <span class="c1"># Let&#39;s generate some fake data</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mglearn</span><span class="o">.</span><span class="n">discrete_scatter</span><span class="p">(</span><span class="n">X_toy</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_toy</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">y_toy</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Feature 0&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Feature 1&quot;</span><span class="p">)</span>
<span class="n">svm</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s2">&quot;rbf&quot;</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_toy</span><span class="p">,</span> <span class="n">y_toy</span><span class="p">)</span>
<span class="n">mglearn</span><span class="o">.</span><span class="n">plots</span><span class="o">.</span><span class="n">plot_2d_separator</span><span class="p">(</span><span class="n">svm</span><span class="p">,</span> <span class="n">X_toy</span><span class="p">,</span> <span class="n">fill</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.4</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/04_kNNs-SVM-RBF_111_0.png" src="../_images/04_kNNs-SVM-RBF_111_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">svm</span><span class="o">.</span><span class="n">support_</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([ 3,  8,  9, 14, 19,  1,  4,  6, 17], dtype=int32)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_support_vectors</span><span class="p">(</span><span class="n">svm</span><span class="p">,</span> <span class="n">X_toy</span><span class="p">,</span> <span class="n">y_toy</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/04_kNNs-SVM-RBF_113_0.png" src="../_images/04_kNNs-SVM-RBF_113_0.png" />
</div>
</div>
<p>The support vectors are the bigger points in the plot above.</p>
</section>
<section id="hyperparameters-of-svm">
<h3>Hyperparameters of SVM<a class="headerlink" href="#hyperparameters-of-svm" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>Key hyperparameters of <code class="docutils literal notranslate"><span class="pre">rbf</span></code> SVM are</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">gamma</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">C</span></code></p></li>
</ul>
</li>
<li><p>We are not equipped to understand the meaning of these parameters at this point but you are expected to describe their relation to the fundamental tradeoff.</p></li>
</ul>
<p>See <a class="reference external" href="https://scikit-learn.org/stable/auto_examples/svm/plot_rbf_parameters.html"><code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code>’s explanation of RBF SVM parameters</a>.</p>
</section>
<section id="relation-of-gamma-and-the-fundamental-trade-off">
<h3>Relation of <code class="docutils literal notranslate"><span class="pre">gamma</span></code> and the fundamental trade-off<a class="headerlink" href="#relation-of-gamma-and-the-fundamental-trade-off" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">gamma</span></code> controls the complexity (fundamental trade-off), just like other hyperparameters we’ve seen.</p>
<ul>
<li><p>larger <code class="docutils literal notranslate"><span class="pre">gamma</span></code> <span class="math notranslate nohighlight">\(\rightarrow\)</span> more complex</p></li>
<li><p>smaller <code class="docutils literal notranslate"><span class="pre">gamma</span></code> <span class="math notranslate nohighlight">\(\rightarrow\)</span> less complex</p></li>
</ul>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">gamma</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">]</span>
<span class="n">plot_svc_gamma</span><span class="p">(</span>
    <span class="n">gamma</span><span class="p">,</span>
    <span class="n">X_train</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(),</span>
    <span class="n">y_train</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(),</span>
    <span class="n">x_label</span><span class="o">=</span><span class="s2">&quot;longitude&quot;</span><span class="p">,</span>
    <span class="n">y_label</span><span class="o">=</span><span class="s2">&quot;latitude&quot;</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/04_kNNs-SVM-RBF_117_0.png" src="../_images/04_kNNs-SVM-RBF_117_0.png" />
</div>
</div>
</section>
<section id="relation-of-c-and-the-fundamental-trade-off">
<h3>Relation of <code class="docutils literal notranslate"><span class="pre">C</span></code> and the fundamental trade-off<a class="headerlink" href="#relation-of-c-and-the-fundamental-trade-off" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">C</span></code> <em>also</em> affects the fundamental tradeoff</p>
<ul>
<li><p>larger <code class="docutils literal notranslate"><span class="pre">C</span></code> <span class="math notranslate nohighlight">\(\rightarrow\)</span> more complex</p></li>
<li><p>smaller <code class="docutils literal notranslate"><span class="pre">C</span></code> <span class="math notranslate nohighlight">\(\rightarrow\)</span> less complex</p></li>
</ul>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">C</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">100.0</span><span class="p">,</span> <span class="mf">1000.0</span><span class="p">,</span> <span class="mf">100000.0</span><span class="p">]</span>
<span class="n">plot_svc_C</span><span class="p">(</span>
    <span class="n">C</span><span class="p">,</span> <span class="n">X_train</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(),</span> <span class="n">y_train</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(),</span> <span class="n">x_label</span><span class="o">=</span><span class="s2">&quot;longitude&quot;</span><span class="p">,</span> <span class="n">y_label</span><span class="o">=</span><span class="s2">&quot;latitude&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/04_kNNs-SVM-RBF_119_0.png" src="../_images/04_kNNs-SVM-RBF_119_0.png" />
</div>
</div>
</section>
<section id="search-over-multiple-hyperparameters">
<h3>Search over multiple hyperparameters<a class="headerlink" href="#search-over-multiple-hyperparameters" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>So far you have seen how to carry out search over a hyperparameter</p></li>
<li><p>In the above case the best training error is achieved by the most complex model (large <code class="docutils literal notranslate"><span class="pre">gamma</span></code>, large <code class="docutils literal notranslate"><span class="pre">C</span></code>).</p></li>
<li><p>Best validation error requires a hyperparameter search to balance the fundamental tradeoff.</p>
<ul>
<li><p>In general we can’t search them one at a time.</p></li>
<li><p>More on this next week. But if you cannot wait till then, you may look up the following:</p>
<ul>
<li><p><a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html">sklearn.model_selection.GridSearchCV</a></p></li>
<li><p><a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html">sklearn.model_selection.RandomizedSearchCV</a></p></li>
</ul>
</li>
</ul>
</li>
</ul>
</section>
<section id="svm-regressor">
<h3>SVM Regressor<a class="headerlink" href="#svm-regressor" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>Similar to KNNs, you can use SVMs for regression problems as well.</p></li>
<li><p>See <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html"><code class="docutils literal notranslate"><span class="pre">sklearn.svm.SVR</span></code></a> for more details.</p></li>
</ul>
</section>
</section>
<section id="id1">
<h2>❓❓ Questions for you<a class="headerlink" href="#id1" title="Permalink to this headline">#</a></h2>
</section>
<section id="iclicker-exercise-4-2">
<h2>(iClicker) Exercise 4.2<a class="headerlink" href="#iclicker-exercise-4-2" title="Permalink to this headline">#</a></h2>
<p><strong>iClicker cloud join link: https://join.iclicker.com/3DP5H</strong></p>
<p><strong>Select all of the following statements which are TRUE.</strong></p>
<ol class="simple">
<li><p><span class="math notranslate nohighlight">\(k\)</span>-NN may perform poorly in high-dimensional space (say, <em>d</em> &gt; 1000).</p></li>
<li><p>In SVM RBF, removing a non-support vector would not change the decision boundary.</p></li>
<li><p>In sklearn’s SVC classifier, large values of gamma tend to result in higher training score but probably lower validation score.</p></li>
<li><p>If we increase both gamma and C, we can’t be certain if the model becomes more complex or less complex.</p></li>
</ol>
<section id="more-practice-questions">
<h3>More practice questions<a class="headerlink" href="#more-practice-questions" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>Check out some more practice questions <a class="reference external" href="https://ml-learn.mds.ubc.ca/en/module4">here</a>.</p></li>
</ul>
</section>
</section>
<section id="summary">
<h2>Summary<a class="headerlink" href="#summary" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p>We have KNNs and SVMs as new supervised learning techniques in our toolbox.</p></li>
<li><p>These are analogy-based learners and the idea is to assign nearby points the same label.</p></li>
<li><p>Unlike decision trees, all features are equally important.</p></li>
<li><p>Both can be used for classification or regression (much like the other methods we’ve seen).</p></li>
</ul>
<section id="coming-up">
<h3>Coming up:<a class="headerlink" href="#coming-up" title="Permalink to this headline">#</a></h3>
<p>Lingering questions:</p>
<ul class="simple">
<li><p>Are we ready to do machine learning on real-world datasets?</p></li>
<li><p>What would happen if we use <span class="math notranslate nohighlight">\(k\)</span>-NNs or SVM RBFs on the spotify dataset from hw1?</p></li>
<li><p>What happens if we have missing values in our data?</p></li>
<li><p>What do we do if we have features with categories or string values?</p></li>
</ul>
<p><img alt="" src="../_images/eva-seeyou.png" /></p>
</section>
</section>
</section>


<script type="application/vnd.jupyter.widget-state+json">
{"state": {"647016fbe71845859d2723499f13dcec": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "4ad6dfb7cec5420a876d2158e81cf1e6": {"model_name": "SliderStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "SliderStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "StyleView", "description_width": "", "handle_color": null}}, "0955c5d6d6a14cd19d24de0a14fcbd5c": {"model_name": "IntSliderModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "IntSliderModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "2.0.0", "_view_name": "IntSliderView", "behavior": "drag-tap", "continuous_update": true, "description": "n_neighbors", "description_allow_html": false, "disabled": false, "layout": "IPY_MODEL_647016fbe71845859d2723499f13dcec", "max": 10, "min": 1, "orientation": "horizontal", "readout": true, "readout_format": "d", "step": 2, "style": "IPY_MODEL_4ad6dfb7cec5420a876d2158e81cf1e6", "tabbable": null, "tooltip": null, "value": 1}}, "1da1d92d6993404b9af1e678f89d2b7e": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "c1f1fceb8d8a4da28b74af004498549c": {"model_name": "VBoxModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": ["widget-interact"], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "VBoxModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "2.0.0", "_view_name": "VBoxView", "box_style": "", "children": ["IPY_MODEL_0955c5d6d6a14cd19d24de0a14fcbd5c", "IPY_MODEL_7b9d3789b53c408e8198edaa313fa7fb"], "layout": "IPY_MODEL_1da1d92d6993404b9af1e678f89d2b7e", "tabbable": null, "tooltip": null}}, "c0c9af096d0e4e4987ff5e9e7b49c443": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "7b9d3789b53c408e8198edaa313fa7fb": {"model_name": "OutputModel", "model_module": "@jupyter-widgets/output", "model_module_version": "1.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/output", "_model_module_version": "1.0.0", "_model_name": "OutputModel", "_view_count": null, "_view_module": "@jupyter-widgets/output", "_view_module_version": "1.0.0", "_view_name": "OutputView", "layout": "IPY_MODEL_c0c9af096d0e4e4987ff5e9e7b49c443", "msg_id": "", "outputs": [{"output_type": "stream", "name": "stdout", "text": "n_neighbors 1\n"}, {"output_type": "display_data", "metadata": {}, "data": {"text/plain": "<Figure size 640x480 with 1 Axes>", "image/png": "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\n"}}], "tabbable": null, "tooltip": null}}, "991ac8afbda04f5d91b440cb765e4804": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "912e64a5c936499f9268c7a80451185b": {"model_name": "SliderStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "SliderStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "StyleView", "description_width": "", "handle_color": null}}, "ca2b2b92b9ee484da94c9bb7cc6c0011": {"model_name": "IntSliderModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "IntSliderModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "2.0.0", "_view_name": "IntSliderView", "behavior": "drag-tap", "continuous_update": true, "description": "n_neighbors", "description_allow_html": false, "disabled": false, "layout": "IPY_MODEL_991ac8afbda04f5d91b440cb765e4804", "max": 101, "min": 1, "orientation": "horizontal", "readout": true, "readout_format": "d", "step": 5, "style": "IPY_MODEL_912e64a5c936499f9268c7a80451185b", "tabbable": null, "tooltip": null, "value": 1}}, "90ee2ac1f1f14f28a0cb00b33db74268": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "5faf5e1e842349e3b27ae2b53353222d": {"model_name": "VBoxModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": ["widget-interact"], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "VBoxModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "2.0.0", "_view_name": "VBoxView", "box_style": "", "children": ["IPY_MODEL_ca2b2b92b9ee484da94c9bb7cc6c0011", "IPY_MODEL_b5845eb059c24756b891f3600d0a4551"], "layout": "IPY_MODEL_90ee2ac1f1f14f28a0cb00b33db74268", "tabbable": null, "tooltip": null}}, "2b368b8639b94011b1e19f86f9264d58": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "b5845eb059c24756b891f3600d0a4551": {"model_name": "OutputModel", "model_module": "@jupyter-widgets/output", "model_module_version": "1.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/output", "_model_module_version": "1.0.0", "_model_name": "OutputModel", "_view_count": null, "_view_module": "@jupyter-widgets/output", "_view_module_version": "1.0.0", "_view_name": "OutputView", "layout": "IPY_MODEL_2b368b8639b94011b1e19f86f9264d58", "msg_id": "", "outputs": [{"output_type": "stream", "name": "stdout", "text": "   n_neighbours  mean_train_score  mean_valid_score\n0             1               1.0             0.755\n"}], "tabbable": null, "tooltip": null}}}, "version_major": 2, "version_minor": 0}
</script>


    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "conda-env-cpsc330-py"
        },
        kernelOptions: {
            kernelName: "conda-env-cpsc330-py",
            path: "./lectures"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'conda-env-cpsc330-py'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="03_ml-fundamentals.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Lecture 3: Machine Learning Fundamentals</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="05_preprocessing-pipelines.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Lecture 5: Preprocessing and <code class="docutils literal notranslate"><span class="pre">sklearn</span></code> pipelines</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Varada Kolhatkar<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>